"""
ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã®è©³ç´°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ„ãƒ¼ãƒ«

å„å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè¡Œæ™‚é–“ã‚’è©³ç´°ã«è¨ˆæ¸¬ã—ã€ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç‰¹å®šã—ã¾ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    uv run tools/profile_upload.py [ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹]
    uv run tools/profile_upload.py data/sample.xlsx
    uv run tools/profile_upload.py --all  # ã™ã¹ã¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¸¬å®š
"""

import sys
import time
import base64
from pathlib import Path
from dataclasses import dataclass, field
from typing import Dict, List
import json

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.config import get_config
from src.protocol.server import KnowledgeBaseMCPServer
from src.services.document import DocumentService
from src.protocol.schemas import UploadDocumentInput


@dataclass
class StepTiming:
    """å„ã‚¹ãƒ†ãƒƒãƒ—ã®è¨ˆæ¸¬çµæœ"""
    name: str
    duration: float  # ç§’
    metadata: Dict = field(default_factory=dict)


@dataclass
class ProfileResult:
    """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°çµæœå…¨ä½“"""
    file_path: str
    file_size_kb: float
    total_time: float
    steps: List[StepTiming]
    
    def print_report(self):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›"""
        print("\n" + "=" * 80)
        print(f"ğŸ“Š Upload Performance Profile: {Path(self.file_path).name}")
        print("=" * 80)
        print(f"File Size: {self.file_size_kb:.2f} KB")
        print(f"Total Time: {self.total_time:.3f}s")
        print()
        
        # ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®è©³ç´°
        print(f"{'Step':<30} {'Time (s)':>12} {'%':>8} {'Details':>20}")
        print("-" * 80)
        
        for step in self.steps:
            percentage = (step.duration / self.total_time * 100) if self.total_time > 0 else 0
            
            # è©³ç´°æƒ…å ±ã®æŠ½å‡º
            details = []
            if "chunks" in step.metadata:
                details.append(f"{step.metadata['chunks']} chunks")
            if "documents" in step.metadata:
                details.append(f"{step.metadata['documents']} docs")
            if "vectors" in step.metadata:
                details.append(f"{step.metadata['vectors']} vectors")
            if "time_per_chunk" in step.metadata:
                details.append(f"{step.metadata['time_per_chunk']:.3f}s/chunk")
            
            details_str = ", ".join(details) if details else "-"
            
            print(f"{step.name:<30} {step.duration:>12.3f} {percentage:>7.1f}% {details_str:>20}")
        
        print("=" * 80)
        
        # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æ
        sorted_steps = sorted(self.steps, key=lambda x: x.duration, reverse=True)
        print("\nğŸ” Bottleneck Analysis (Top 3):")
        for i, step in enumerate(sorted_steps[:3], 1):
            percentage = (step.duration / self.total_time * 100) if self.total_time > 0 else 0
            print(f"  {i}. {step.name}: {step.duration:.3f}s ({percentage:.1f}%)")
        print()


class UploadProfiler:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼"""
    
    def __init__(self):
        self.config = get_config()
        self.server = KnowledgeBaseMCPServer(self.config)
        self.server.initialize()
        
        # DocumentServiceã‚’ä½¿ç”¨ï¼ˆå®Œå…¨ãªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ãƒ­ãƒ¼ï¼‰
        self.document_service = DocumentService(
            vectorstore_service=self.server.vectorstore_service,
            embedding_service=self.server.embedding_service,
            config=self.config
        )
    
    def profile_file(self, file_path: Path, domain: str = "benchmark") -> ProfileResult:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã‚’ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°"""
        
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")
        
        file_size_kb = file_path.stat().st_size / 1024
        steps = []
        overall_start = time.time()
        
        # Step 1: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ & Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        print(f"ğŸ”„ Step 1/3: File Loading & Encoding...")
        start = time.time()
        with open(file_path, 'rb') as f:
            file_bytes = f.read()
        file_content_b64 = base64.b64encode(file_bytes).decode('utf-8')
        duration = time.time() - start
        steps.append(StepTiming(
            name="1. File I/O & Encoding",
            duration=duration,
            metadata={"bytes": len(file_bytes)}
        ))
        
        # Step 2-3: å®Œå…¨ãªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ãƒ­ãƒ¼
        # ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå¤‰æ›ã€ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã€ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã€ãƒ™ã‚¯ãƒˆãƒ«DBæ ¼ç´ï¼‰
        print(f"ğŸ”„ Step 2-3: Complete Upload Flow (Save + Vectorize)...")
        start = time.time()
        
        # DocumentServiceã‚’ä½¿ç”¨ã—ã¦å®Œå…¨ãªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        upload_path = f"{domain}/{file_path.name}"
        upload_input = UploadDocumentInput(
            path=upload_path,
            content=file_content_b64,
            encoding="base64",
            overwrite=True
        )
        
        result = self.document_service.upload_document(upload_input)
        
        duration = time.time() - start
        
        steps.append(StepTiming(
            name="2-3. Complete Upload (Save + Convert + Split + Embed + Store)",
            duration=duration,
            metadata={
                "chunks": result.chunks_created,
                "time_per_chunk": duration / result.chunks_created if result.chunks_created > 0 else 0,
                "status": result.status
            }
        ))
        
        total_time = time.time() - overall_start
        
        return ProfileResult(
            file_path=str(file_path),
            file_size_kb=file_size_kb,
            total_time=total_time,
            steps=steps
        )
    
    def cleanup(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            self.server.close()
        except Exception as e:
            print(f"Warning: Cleanup error: {e}")


def create_benchmark_files(output_dir: Path):
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç”¨ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    output_dir.mkdir(parents=True, exist_ok=True)
    
    try:
        import pandas as pd
        
        # æ§˜ã€…ãªã‚µã‚¤ã‚ºã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        sizes = {
            "small_1kb": 10,      # 10è¡Œ
            "medium_10kb": 100,   # 100è¡Œ
            "large_100kb": 1000,  # 1000è¡Œ
        }
        
        created_files = []
        for name, rows in sizes.items():
            file_path = output_dir / f"benchmark_{name}.xlsx"
            
            # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            data = {
                "ID": list(range(1, rows + 1)),
                "Name": [f"Item {i}" for i in range(1, rows + 1)],
                "Description": [f"This is a description for item {i} with some additional text to make it longer" for i in range(1, rows + 1)],
                "Value": [i * 1.5 for i in range(1, rows + 1)],
                "Category": [f"Category {i % 10}" for i in range(1, rows + 1)],
            }
            
            df = pd.DataFrame(data)
            df.to_excel(file_path, index=False)
            
            created_files.append(file_path)
            print(f"âœ… Created: {file_path.name} ({file_path.stat().st_size / 1024:.1f} KB)")
        
        return created_files
    
    except ImportError:
        print("âŒ pandas not available, cannot create benchmark files")
        return []


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Profile upload performance")
    parser.add_argument("file", nargs="?", help="File to profile")
    parser.add_argument("--all", action="store_true", help="Profile all benchmark files")
    parser.add_argument("--create", action="store_true", help="Create benchmark files")
    parser.add_argument("--output", default="summary/benchmark", help="Output directory for results")
    
    args = parser.parse_args()
    
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    if args.create:
        benchmark_dir = Path("data/benchmark")
        create_benchmark_files(benchmark_dir)
        return
    
    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Ÿè¡Œ
    profiler = UploadProfiler()
    
    try:
        if args.all:
            # ã™ã¹ã¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¸¬å®š
            benchmark_dir = Path("data/benchmark")
            if not benchmark_dir.exists():
                print("âŒ Benchmark directory not found. Run with --create first.")
                return
            
            files = sorted(benchmark_dir.glob("benchmark_*.xlsx"))
            if not files:
                print("âŒ No benchmark files found. Run with --create first.")
                return
            
            results = []
            for file_path in files:
                print(f"\n{'='*80}")
                print(f"Profiling: {file_path.name}")
                print(f"{'='*80}")
                
                result = profiler.profile_file(file_path)
                result.print_report()
                results.append(result)
            
            # ã‚µãƒãƒªãƒ¼ä¿å­˜
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            summary_file = output_dir / f"profile_summary_{timestamp}.json"
            
            summary_data = {
                "timestamp": timestamp,
                "results": [
                    {
                        "file": result.file_path,
                        "file_size_kb": result.file_size_kb,
                        "total_time": result.total_time,
                        "steps": [
                            {
                                "name": step.name,
                                "duration": step.duration,
                                "metadata": step.metadata
                            }
                            for step in result.steps
                        ]
                    }
                    for result in results
                ]
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, indent=2, ensure_ascii=False)
            
            print(f"\nğŸ“„ Summary saved to: {summary_file}")
        
        elif args.file:
            # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¸¬å®š
            file_path = Path(args.file)
            result = profiler.profile_file(file_path)
            result.print_report()
            
            # çµæœã‚’ä¿å­˜
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            result_file = output_dir / f"profile_{file_path.stem}_{timestamp}.txt"
            
            # ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ä¿å­˜
            with open(result_file, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write(f"ğŸ“Š Upload Performance Profile: {file_path.name}\n")
                f.write("=" * 80 + "\n")
                f.write(f"File Size: {result.file_size_kb:.2f} KB\n")
                f.write(f"Total Time: {result.total_time:.3f}s\n")
                f.write("\n")
                
                f.write(f"{'Step':<30} {'Time (s)':>12} {'%':>8} {'Details':>20}\n")
                f.write("-" * 80 + "\n")
                
                for step in result.steps:
                    percentage = (step.duration / result.total_time * 100) if result.total_time > 0 else 0
                    
                    details = []
                    if "chunks" in step.metadata:
                        details.append(f"{step.metadata['chunks']} chunks")
                    if "documents" in step.metadata:
                        details.append(f"{step.metadata['documents']} docs")
                    if "time_per_chunk" in step.metadata:
                        details.append(f"{step.metadata['time_per_chunk']:.3f}s/chunk")
                    
                    details_str = ", ".join(details) if details else "-"
                    f.write(f"{step.name:<30} {step.duration:>12.3f} {percentage:>7.1f}% {details_str:>20}\n")
                
                f.write("=" * 80 + "\n")
                
                # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æ
                sorted_steps = sorted(result.steps, key=lambda x: x.duration, reverse=True)
                f.write("\nğŸ” Bottleneck Analysis (Top 3):\n")
                for i, step in enumerate(sorted_steps[:3], 1):
                    percentage = (step.duration / result.total_time * 100) if result.total_time > 0 else 0
                    f.write(f"  {i}. {step.name}: {step.duration:.3f}s ({percentage:.1f}%)\n")
            
            print(f"\nğŸ“„ Result saved to: {result_file}")
        
        else:
            parser.print_help()
    
    finally:
        profiler.cleanup()


if __name__ == "__main__":
    main()
